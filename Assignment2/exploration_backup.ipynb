{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Dask:</b> Multiprocessing package that can be used for (almost all) Pandas & Scikit-learn functionality.\n",
    " Ships with Anaconda, but not with MiniConda.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "#from dklearn.grid_search import GridSearchCV   # voorbeeld van dklearn => dit gaan we zeker nodig hebben bij hyperopt etc.\n",
    "# from dask.distributed import Client\n",
    "# client = Client() # often http://localhost:8787/status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%timeit -n 1 -r 1\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "path_dominic = 'C:/Users/doist/OneDrive/Documenten/Business Analytics/Master/Year 1/Data Mining Techniques/Assignment 2/Data/'\n",
    "path_titus = '2nd-assignment-dmt-2021/'\n",
    "\n",
    "use_dominic = False\n",
    "dir = path_dominic if use_dominic else path_titus\n",
    "\n",
    "df = pd.read_csv(dir+'training_set_VU_DM.csv', parse_dates=['date_time'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mem_size = df.memory_usage(index=True).sum() / 1_024**2\n",
    "\n",
    "print(f\"Size in Memory: {mem_size:.0f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Inspect inferred types\n",
    "display(df.dtypes)\n",
    "\n",
    "# Inspect numerical ranges\n",
    "display(df.describe())\n",
    "# print('Min. Values')\n",
    "# print(df.min())\n",
    "#\n",
    "# print('Max. Values')\n",
    "# print(df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# data types\n",
    "\n",
    "# # memory + speed improvements\n",
    "# optimal_dtypes = {'srch_id': np.uint32,\n",
    "#                   'site_id': np.uint32,\n",
    "#                   'visitor_location_country_id': np.uint8,\n",
    "#                   'prop_country_id': np.uint8,\n",
    "#                   'prop_id': np.uint32,\n",
    "#                   'prop_starrating': np.uint8,\n",
    "#                   'prop_brand_bool': np.uint8,\n",
    "#                   'promotion_flag': (np.uint8,\n",
    "#                   'srch_destination_id': np.uint16,\n",
    "#                   'srch_length_of_stay': np.uint16,\n",
    "#                   'srch_booking_window': np.uint16,\n",
    "#                   'srch_adults_count': np.uint8,\n",
    "#                   'srch_children_count': np.uint8,  # 255 kids max should suffice\n",
    "#                   'srch_room_count': np.uint8,\n",
    "#                   'srch_saturday_night_bool': np.uint8,\n",
    "#                   'random_bool': np.uint8,\n",
    "#                   'position': np.uint8,\n",
    "#                   'click_bool': np.uint8,\n",
    "#                   'booking_bool': np.uint8}\n",
    "#\n",
    "# for i in range(1, 9):\n",
    "#     optimal_dtypes[f'comp{i}_rate'] = np.int8,\n",
    "#     optimal_dtypes[f'comp{i}_inv'] = np.int8,     # assignment does not specify -1 but is exists??\n",
    "#     # competitor_dtypes[f'comp{i}_rate_percent_diff'] = np.uint\n",
    "\n",
    "\n",
    "# dfn = df.dtypes(optimal_dtypes)\n",
    "# print(dfn.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Count of unique values per column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "uniques = df.nunique()\n",
    "display(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### % missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "missing_percent = 100 * df.isnull().sum() / df.shape[0]\n",
    "display(missing_percent)\n",
    "\n",
    "filled_columns = missing_percent[missing_percent == 0].index.tolist()\n",
    "print(\"Non-missing columns:\")\n",
    "display(filled_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Searches per website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "groupby_website = df.groupby('site_id')['srch_id'].nunique() / df['srch_id'].nunique()\n",
    "\n",
    "site_searches =  groupby_website.sort_values(ascending=False)\n",
    "display(site_searches)\n",
    "# site 5 == 'expedia.com'??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Clicks/Books per position, grouped by random_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# groupby_random_bool = df.groupby('random_bool')[['click_bool', 'booking_bool']].count()\n",
    "groupby_position = df.groupby(['random_bool', 'position'])[['click_bool', 'booking_bool']].sum()\n",
    "groupby_random_bool = groupby_position.groupby('random_bool').sum()\n",
    "click_book_ratio = groupby_position / groupby_random_bool\n",
    "display(groupby_position)\n",
    "display(groupby_random_bool)\n",
    "display(click_book_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Location distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "groupby_home_country = df.groupby('visitor_location_country_id')['srch_id'].nunique()\n",
    "distribution_home_country = 100 * (groupby_home_country / df['srch_id'].nunique()).sort_values(ascending=False)\n",
    "display(distribution_home_country)\n",
    "# Country 219 == USA??\n",
    "# Country 100 == UK?? => Ursu (2015) suggests South-korea\n",
    "\n",
    "groupby_prop_country = df.groupby('prop_country_id')['srch_id'].nunique()\n",
    "distribution_prop_country = 100 * (groupby_prop_country / df['srch_id'].nunique()).sort_values(ascending=False)\n",
    "display(distribution_prop_country)\n",
    "\n",
    "groupby_destination_id = df.groupby('srch_destination_id')['srch_id'].nunique()\n",
    "distribution_destination_id = 100 * (groupby_destination_id / df['srch_id'].nunique()).sort_values(ascending=False)\n",
    "display(distribution_destination_id)\n",
    "\n",
    "# 8192 == NYC??\n",
    "# 4562 == LA?? Miami??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "competitor_cols = []\n",
    "for i in range(1, 9):\n",
    "    competitor_cols += [f'comp{i}_rate', f'comp{i}_inv', f'comp{i}_rate_percent_diff']\n",
    "drop_cols = competitor_cols + ['gross_bookings_usd', 'position']\n",
    "\n",
    "df_stage1 = df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### More Drops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# left-over with missings\n",
    "left_overs = [col\n",
    "              for col in df_stage1.columns\n",
    "              if not col in filled_columns]\n",
    "print(\"Left-over columns for drop/imputation\")\n",
    "display(missing_percent[left_overs])\n",
    "drop_cols_extra = ['visitor_hist_starrating', 'visitor_hist_adr_usd', 'srch_query_affinity_score']  # voor nu even droppen\n",
    "df_stage1.drop(columns=drop_cols_extra, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fill Na\n",
    "### TODO: prop_review_score per DMT 2020 group 95\n",
    "#### prop_review_score & prop_location_score2 imputed per country, lower quantile as baseline => cited by VU boys and Liu et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "prop_score = df_stage1.groupby('prop_id')['prop_review_score'].max()\n",
    "no_reviews = prop_score[prop_score == 0].index\n",
    "display(no_reviews)\n",
    "print(f\"% properties with no reviews {100 * len(no_reviews) / len(prop_score)}\")\n",
    "\n",
    "# lots of properties with no reviews ever\n",
    "# option 1: keep imputing like papers do\n",
    "# option 2: use backfill if reviews show up later and then impute like papers do\n",
    "# temporarily drop prop_review_score until decision made\n",
    "df_stage1.drop(columns=['prop_review_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# grouped by 'srch_destination_id' (city) would be more precise, but still has some NaN's\n",
    "country_score2 = df_stage1.groupby('prop_country_id')['prop_location_score2'].quantile(0.25)\n",
    "\n",
    "score2_country_join = pd.merge(df_stage1, country_score2, on='prop_country_id', how='left')['prop_location_score2_y']\n",
    "print(f\"Still {score2_country_join.isnull().sum()} unsolved NaN's\")\n",
    "\n",
    "# Fill 2 left-overs\n",
    "score2_country_join[score2_country_join.isnull()] = country_score2.mean()\n",
    "print(f\"Still {score2_country_join.isnull().sum()} unsolved NaN's\")\n",
    "\n",
    "df_stage2 = df_stage1.copy()\n",
    "nan_mask = df_stage2['prop_location_score2'].isnull()\n",
    "display(nan_mask)\n",
    "df_stage2.loc[nan_mask, 'prop_location_score2'] = score2_country_join[nan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Impute distance matrix using shortest path\n",
    "# drop for now\n",
    "df_stage2.drop(columns=['orig_destination_distance'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Group 95 does not give an alpha => this needs reasoning\n",
    "alpha = 0.01\n",
    "price_usd = df_stage2['price_usd']\n",
    "price_usd_winsorized = price_usd.clip(lower=price_usd.quantile(alpha), upper=price_usd.quantile(1-alpha))\n",
    "\n",
    "display(price_usd_winsorized)\n",
    "outliers = price_usd[price_usd != price_usd_winsorized]\n",
    "display(outliers)\n",
    "\n",
    "df_stage3 = df_stage2.copy()\n",
    "df_stage3['price_usd'] = price_usd_winsorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Temporary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "missing_percent = 100 * df_stage3.isnull().sum() / df_stage3.shape[0]\n",
    "print(\"% missing:\")\n",
    "display(missing_percent)\n",
    "\n",
    "df_stage3.to_pickle('df_temporary.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feature engineering:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check class inbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('click_bool')['srch_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('booking_bool')['srch_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Total instances not clicked and not booked = ', df.groupby('click_bool')['srch_id'].count()[0])\n",
    "print('Total instances clicked but not booked = ', (df.groupby('click_bool')['srch_id'].count()[1]-df.groupby('booking_bool')['srch_id'].count()[1]))\n",
    "print('Total instances clicked and booked = ', df.groupby('booking_bool')['srch_id'].count()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Check if it is true that all instances booked are also clicked:\n",
    "df[df['booking_bool']==1]['click_bool'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def boxplot_compare(column):\n",
    "    not_clicked_not_booked = df.loc[(df.click_bool==0) & (df.booking_bool==0)][column]\n",
    "    clicked_not_booked = df.loc[(df.click_bool==1) & (df.booking_bool==0)][column]\n",
    "    clicked_and_booked = df.loc[df.booking_bool==1][column]\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    sns.boxplot(data=[not_clicked_not_booked, clicked_not_booked, clicked_and_booked])\n",
    "    plt.xticks(plt.xticks()[0], ['Not clicked or booked', 'Clicked but not booked', 'Booked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "boxplot_compare('position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "boxplot_compare('prop_starrating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "boxplot_compare('prop_review_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "boxplot_compare('prop_location_score1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('booking_bool')['promotion_flag'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('click_bool')['promotion_flag'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is a correlation between variables and position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_non_random = df[df['random_bool']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='prop_review_score', y='position', data=df_non_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='prop_starrating', y='position', data=df_non_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bookings seasonality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stage3['checkin_date'] = df_stage3['date_time'] + pd.to_timedelta(df_stage3['srch_booking_window'], unit='D')  # speedup with vectorize?,\n",
    "display(df_stage3[['date_time', 'checkin_date']])\n",
    "df_stage3['checkin_weeknr'] = df_stage3['checkin_date'].dt.isocalendar().week\n",
    "\n",
    "groupby_weeknr = df_stage3.groupby('checkin_weeknr')['srch_id'].nunique()\n",
    "distr_weeknr = groupby_weeknr / df_stage3['srch_id'].nunique()\n",
    "display(groupby_weeknr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x = distr_weeknr.index.tolist()\n",
    "y = distr_weeknr.values\n",
    "\n",
    "ax.bar(x, y, 0.1, color='r')\n",
    "ax.set_ylabel('Booking Ratio')\n",
    "ax.set_xlabel('Week Nr.')\n",
    "ax.set_title('Bookings Seasonality')\n",
    "ax.set_title('Bookings Seasonality')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Date Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mine_date_features(dt_series, prefix=''):\n",
    "        df = pd.DataFrame()\n",
    "        df['weekday'] = dt_series.dt.weekday\n",
    "        df['monthday'] = dt_series.dt.day\n",
    "        df['month'] = dt_series.dt.month\n",
    "        df['week'] = dt_series.dt.week\n",
    "        df['year'] = dt_series.dt.year\n",
    "    \n",
    "        df.columns = list(map(lambda s: prefix + s, df.columns.tolist()))\n",
    "        return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stage3['checkout_date'] = df_stage3['checkin_date'] + pd.to_timedelta(df_stage3['srch_length_of_stay'], unit='D')\n",
    "\n",
    "df_srchdate_features = mine_date_features(df_stage3['date_time'], prefix='srchdate_')\n",
    "df_srchdate_features['srchdate_hour'] = df_stage3['date_time'].dt.hour\n",
    "\n",
    "df_checkin_features = mine_date_features(df_stage3['checkin_date'], prefix='checkin_')\n",
    "df_checkout_features = mine_date_features(df_stage3['checkout_date'], prefix='checkout_')\n",
    "\n",
    "df_stage4 = pd.concat([df_stage3, df_srchdate_features, df_checkin_features, df_checkout_features], axis=1)\n",
    "display(df_srchdate_features)\n",
    "display(df_checkin_features)\n",
    "display(df_checkout_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Count # of weekdays contained in booking_window (i.e. Sun: 1, Sat: 1, mon: 1, tue: 0, wed: 0 ...)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import calendar\n",
    "def dayofweek_count(dt_start, dt_end):\n",
    "    dt_range = pd.date_range(dt_start, dt_end, freq='d')\n",
    "\n",
    "    cnt = {day: 0 for day in calendar.day_name}\n",
    "    for date in dt_range:\n",
    "        cnt[date.day_name()] += 1\n",
    "    return pd.Series(cnt)\n",
    "\n",
    "\n",
    "srch_grouped = df_stage4.groupby('srch_id').first()\n",
    "srch_window = pd.DataFrame(srch_grouped[['checkin_date', 'checkout_date']])\n",
    "display(srch_window)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "srch_daycounts = srch_window.apply(lambda df: dayofweek_count(df['checkin_date'], df['checkout_date']), axis=1)\n",
    "\n",
    "display(srch_daycounts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stage5 = pd.merge(df_stage4, srch_daycounts, on='srch_id', how='left')\n",
    "display(df_stage5.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if join is correct\n",
    "print(df_stage4.shape)\n",
    "print(df_stage5.shape)\n",
    "missings = df_stage5[list(calendar.day_name)].isnull().sum() / df_stage5.shape[0]\n",
    "print(missings)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Holiday Features (if contained in booking window)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import holidays\n",
    "holidays = holidays.UnitedStates(years=[2012, 2013, 2014])  # easter is missing but fuck that"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def booking_contains_holidays(dt_start, dt_end, holidays):\n",
    "    dt_range = [dt.date() for dt in pd.date_range(dt_start, dt_end, freq='D')]\n",
    "\n",
    "    contained = defaultdict(bool)\n",
    "    for dt_holiday, name_holiday in holidays.items():\n",
    "        if contained[name_holiday]: # prevents override of holiday from another year\n",
    "            continue\n",
    "\n",
    "        contained[name_holiday] = dt_holiday in dt_range\n",
    "    return pd.Series(contained)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "srch_holidays = srch_window.apply(lambda df: booking_contains_holidays(df['checkin_date'], df['checkout_date'], holidays), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nr_of_holidays = (srch_holidays == True).sum()\n",
    "print(nr_of_holidays)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stage6 = pd.merge(df_stage5, srch_holidays, on='srch_id', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pricing features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_prop = df[['prop_id', 'srch_id', 'date_time', 'price_usd']].set_index(['prop_id', 'date_time']).sort_index()\n",
    "\n",
    "df_prop['last_price'] = df_prop.groupby(level=0)['price_usd'].shift().fillna(df_prop['price_usd'])  # use same price\n",
    "df_prop['diff_last_price'] = (df_prop['price_usd'] - df_prop['last_price']) / df_prop['last_price']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rolling_min(series):\n",
    "    expand_min = series.expanding().min()\n",
    "\n",
    "    print(series)\n",
    "\n",
    "    \n",
    "df_prop['min_price'] = df_prop[:100].groupby(level=0)['price_usd'].apply(rolling_min)\n",
    "display(df_prop.head(65))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: add price differences per property (from last historic, mean and max)\n",
    "# TODO: price difference whole dataset => Ursu (2015) suggests cheaper properties have more clicks\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: plot search impressions compared to time of day -> compare USA (219) vs rest to check timezone"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: prop_review_score by average of hotel?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "dmt3",
   "language": "python",
   "display_name": "Python (DMT3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}